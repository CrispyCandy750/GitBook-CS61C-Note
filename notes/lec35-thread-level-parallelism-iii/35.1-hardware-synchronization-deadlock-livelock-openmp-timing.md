---
description: 本节内容：1.OpenMP数据竞争与同步问题；2.AMO是什么；3.怎么用AMO解决同步问题；4. OpenMP提供解决同步防蚊贴的语法；5. Deadlock & Livelock；6. OpenMP Timing
---

# 35.1-Hardware Synchronization, Deadlock, Livelock & OpenMP Timing

{% embed url="https://youtu.be/tJ9dqPYGb4E?si=j6zZlvDLcwVGt595" %}
Lecture Video Address
{% endembed %}

## Review

### OpenMP

OpenMP提供了一种抽象，能够很方便的将并行性添加到C代码当中。

1. OpenMP as simple parallel extension to C
    - Threads level programming with parallel for pragma
    - ≈ C: small so easy to learn, but not very high level and it's easy to get into trouble

```c
for (i=0; i<max; i++) zero[i] = 0;
```

2. Breaks for loop into chunks, and allocate each to a separate thread
    - e.g. if max = 100 with 2 threads: assign 0-49 to thread 0, and 50-99 to thread 1

> 划分的时候将连续的内存划分到一个Thread，这样可以提高Cache的hit rate

3. Must have relatively simple "shape" for an OpenMP-aware compiler to be able to parallelize it
    - Necessary for the run-time system to be able to determine how many of the loop iterations to assign to each thread

> 比如说，双层循环就没法很好的并行化，尽量将其解开成为一层循环。

4. No premature exits from the loop allowed

> 代码中不能有提前退出的情况

- i.e. No `break`, `return`, `exit`, `goto` statements
- In general, don't jump outside of any pragma block

### Data Races & Synchronization

1. Two memory accesses form a data race if from different threads access same location, at least one is a write, and they occur one after another

> 但是两个都是读的话就不会产生race condition

2. If there is a data race, result of program varies depending on chance (which thread first?)

3. Avoid data races by synchronizing writing and reading to get deterministic behavior

4. Synchronization done by user-level routines that rely on hardware synchronization instructions

> 在用户级别(HLL)是无法支持synchronization的，需要依靠Hardware

## RISC-V Atomic Memory Operations (AMOs)

> 所有有相关问题的硬件都需要支持硬件同步，并且能够提供给高级语言实现同步的接口。

### Solution

- Atomic read/write
- Read & write in single instruction: No other access permitted between read and write
- Must use shared memory (multiprocessing)

> 也就是说，硬件实现同步的方案就是原子读写，意味着可以在单个指令中进行读写，并且在读写之间不允许其他任何访问。这是在共享内存空间中进行的。
>
> 共享内存空间：两个线程共享的一部分内存空间。

---

### Common implementations

常见的实现方式有如下两种

1. Atomic swap of `register ↔ memory`

> 将`Register ↔ Memory`这个操作设置为原子操作。在原先的RISC-V中，要实现这个需要分三步，例如将mem与rs1进行交换，那么需要先rs2 = rs1，然后rs1 = mem，最后mem = rs2；在底层是由硬件实现的。
>
> 但是为了实现同步，需要有一个指令能够直接实现rs1 ↔ mem，当硬件接受这个指令的时候也能实现这个任务

2. Pair of instructions for "linked" read and write
    - write fails if memory location has been "tampered" with after linked read

> 两一个方法就是用于将读写指令给链接起来。如果在链接读取后内存位置被“篡改”，写操作将失败。

RISC-V has variations of both, but for simplicity we will focus on the **former**

> 这里我们只讲前一种，本节结尾有diss13对于第二种方式的说明

### AMO

> ~到这里，硬件实现同步的方式的思路就明确了，在之前，C语言中的pi=pi+sum[id]会出现多个threads同时读取pi的old-value，然后赋值，这样后面的会覆盖前面的结果，而不是将sum[id]累加。~
>
> ~这样的本质原因就是pi=pi+sum[id]这个操作会被翻译为多个汇编指令，硬件也是一个指令一个指令完成，当完成中间的一条指令的时候就有可能被其他指令给覆盖。~
>
> ~解决办法就是提供一种原子指令，将pi=pi+sum[id]翻译为这种原子指令从而将原先多个指令完成的任务一气呵成，从而避免了多个指令无法立即完成的问题~
>
> 上面这个思路是错误的，硬件解决的不是`pi=pi+sum[id]`这个操作的问题。简单的操作可以原子化，但如果a = a + b + c + d这样的操作或者希望多条语句不被打断就无法原子化了。所以硬件实现同步并不是要将这些内容原子化。下面会有说明。

- AMOs atomically perform an operation on an operand in memory and set the destination register to the original memory value

> 回想一下，如果希望将内存中的5加上10，需要进行的操作是健将内存中的值加载到Register，然后在Register中计算出结果再写回到内存当中，这是一个三步的过程。
>
> AMO(atom memory operation)提供硬件支持，允许用一个指令就完成这三个操作，中间没有其他线程可以打断

- R-Type Instruction Format: `Add`, `And`, `Or`, `Swap`, `Xor`, `Max`, `Max Unsigned`, `Min`, `Min Unsigned`（这些指令都支持AMO）

> 这里的`Add`是支持`mem = mem + reg`，而不是`rd = rs1 + rs2`的操作

如下是AMO的格式，其中opcode表明是AMO

| operation | ordering | ordering | src  | addr | width  | dest | AMO    |
| --------- | -------- | -------- | ---- | ---- | ------ | ---- | ------ |
| funct5    | aq       | rl       | rs2  | rs1  | funct3 | rd   | opcode |
| 5         | 1        | 1        | 5    | 5    | 3      | 5    | 7      |

- **.aq（acquire）**：在此指令之前的所有内存操作都在此指令之前完成。
- **.rl（release）**：在此指令之后的所有内存操作都在此指令之后完成。

### Example: amoadd

以amoadd操作为例

Add指令格式为: 

```assembly
amoadd.w rd, rs2, (rs1)
```

rs1中保存着Memory Address，x[rs1]表示rs1的值

所做的任务如下：

1. `x[rd] = M[x[rs1]]`
2. `M[x[rs1]] = x[rs2] + M[x[rs1]]`

所以这个指令完成了这两步。

---

执行过程如下

```c
t = M[x[rs1]]; // 先将M[x[rs1]]赋值到变量t
x[rd] = t;
M[x[rs1]] = t + x[rs2];
```

在一次操作中，实现了读取旧址，对旧址进行加法，然后将其作为新值放回去，这是一种原子操作。

- i.e., the value in memory Store at address in rs1 the calculation 
- aq(acquire) and rl(release) to insure in order execution

## Hard Synchronization

RISC-V实现同步的关键指令就是swap

### AMO swap

首先来看看swap的作用是什么

```
amoswap.w.aq t1, t0, (a0)
```

这条指令在交换前从内存读取数据并保存到`t1`寄存器，然后将`t0`寄存器的值写入到由`a0`指向的内存地址。使用`.aq`标志可以确保指令的内存顺序性。

- `amoswap`：表示这是一个交换操作。
- `.w`：表示操作的数据宽度是32位（word）。
- `.aq`：表示附加顺序（acquire），是一种内存序列化标志，用于确保内存操作的顺序，这里就是先读取`Mem[a0]`的值到t1，然后再`Mem[a0] = t0`
- `rd`：目标寄存器，这里是`t1`。
- `rs2`：源寄存器，这里是`t0`。
- `rs1`：内存地址寄存器，这里是`a0`。

步骤如下：

1. **读取内存**：从由`rs1`（`a0`）指向的内存地址读取32位数据，并将其存储到目标寄存器`rd`（`t1`）。
2. **交换操作**：将源寄存器`rs2`（`t0`）的值写入由`rs1`（`a0`）指向的内存地址。

### Review: Lock Problem

下面来复习一下之前在软件中使用Lock的问题

```c
// wait for lock released
while (lock != 0) ;
// lock == 0 now (unlocked)

// set lock
lock = 1;
    // access shared resource ...
    // e.g. pi
    // sequential execution! (Amdahl ...)
// release lock
lock = 0; 
```

![不同步](../lec34-thread-level-parallelism-ii/.image/image-20240630154129448.png)

- 这里希望的是`while(lock != 0)` 与 `lock = 1`这两个操作能够一气呵成，在进入循环的同时立即set lock
- 这样就能防止其他的Thread进入。

下面看看RISC-V是如何解决这个问题的。

### RISCV Critical Section

>

解决方式就是将`while(lock != 0)`判断与`lock = 1`设为原子操作。

- lock变量的内存地址存储在寄存器a0中
- The lock is "`set`" if it is 1; it is "`free`" if it is 0 (it's initial value)

过程如下

```assembly
li t0, 1 # Get 1 to set lock
Try: amoswap.w.aq t1, t0, (a0) # t1 gets old lock value
# while we set it to 1
bnez t1, Try # if it was already 1, another
# thread has the lock,
# so we need to try again
… critical section goes here …
amoswap.w.rl x0, x0, (a0) # store 0 in lock to release
```

> critical section(临界区)

分析代码：

- `li t0, 1`: t0寄存器设置为1
- `amoswap.w.aq t1, t0, (a0)`: 将a0地址的变量，也就是lock赋值到t1，将t0的value，也就是1赋予lock

> 这里的`aq`保证先读取lock，然后赋值lock

- `bnez t1, Try`: 当t1不为0，也就是lock不为0的时候，继续循环
- 否则的话，进入critical section，也就是可以同步的块
- `amoswap.w.rl x0, x0, (a0)`，将lock赋值为0

为什么在获取lock的时候需要将其置为1呢

- 当前的Thread需要等到lock为0的时候才能进入循环
- 如果lock此时等于1，那么置为1是没有任何影响的
- 但是，当==**另一个Thread设置lock为0的时候**==，==**swap能够立即读取lock的0并且将lock设置为1**==，这是一个原子操作，阻止了两步之间有其他进程插入

> 实现synchronization并不是将需要同步的过程原子化，而是在这个过程前后使用原子化的操作进行lock和unlock。
>
> 多个线程一直在获取lock并将其设置为1，那么第一个获取lock为0的Thread能够进入critical section

### Lock Synchronization

![amo implements Lock Synchronization](.image/image-20240701155058680.png)

- 在编程的时候，`while(lock != 0);` 和 `lock = 1;`这两个操作仅仅是逻辑上的思路，高级语言这样写是不能实现lock的
- 实现Lock Synchronization是在编译的时候，插入如上的几个汇编指令，由硬件实现Lock

## OpenMP Locks

下面是OpenMP的lock的语法

### syntax

```c
#include<stdio.h>
#include<stdlib.h>
#include<omp.h>

int main(void) {
    omp_lock_t lock;
    omp_init_lock(&lock);

    #pragma omp parallel
    {
        int id = omp_get_thread_num();

        // parallel section
        // ...

        omp_set_lock(&lock);
        // start sequential section
        // ...

        printf("id = %d\n", id);

        // end sequential section
        omp_unset_lock(&lock);

        // parallel section
        // ...
    }

    omp_destroy_lock(&lock);
}
```

- `omp_lock_t lock`声明lock变量
- `omp_init_lock(&lock)`初始化lock
- `omp_set_lock(&lock)`锁定lock，如果lock已经被占住了，那么就会在这里**循环等待**。
- `omp_unset_lock(&lock)`释放lock

要注意的几点：

1. 在`set`与`unset`之间是sequential section，然后前后是Parallel section
2. 这几个接口都是将Lock的操作封装起来。但与普通的接口不一样的是，这些接口底层并不是C语言，而是在编译的时候会翻译为特殊的汇编语言。从而实现Hardware synchronization。
3. 所以实现synchronization的关键就是AMO，Hardware synchronization

### Synchronization In OpenMP

Typically are used in libraries of higher level parallel programming constructs

> 不仅是C语言，其他的高级语言也都会提供相应的接口或者写法来同步并行操作，以确保同一时间只有一个线程可以拥有这些资源(lock或者synchronization)。
>
> 而这些方法是在编译或者解释的时候，通过调用下层的AMO来实现的

---

OpenMP还有其他不同用途的`#pragma`

E.g. OpenMP offers `#pragmas` for common cases:

- critical
- atomic
- barrier
- ordered

OpenMP offers many more features

- E.g., private variables, reductions
- See online documentation
- Or tutorial at [here](http://openmp.org/mp-documents/omp-hands-on-SC08.pdf)

### Example: OpenMP Critical Section(Mutual exclusion)

> Critical Section(临界区)

下面使用使用`#pragma omp critical`的例子，实际效果和之前的效果一样，但是这样的写法更方便，更紧密了。

```c
#include<stdio.h>
#include<omp.h>
void main() {
    const int NUM_THREADS = 1000;
    const long num_steps = 1000000;
    double step = 1.0 / ((double)num_steps);
    double sum[NUM_THREADS];
    double pi = 0;
    for (int i = 0; i < NUM_THREADS; i++)
        sum[i] = 0;

    omp_set_num_threads(NUM_THREADS);

    #pragma omp parallel
    {
        int id = omp_get_thread_num();
        for (int i = id; i < num_steps; i += NUM_THREADS) {
            double x = (i + 0.5) * step;
            sum[id] += 4.0 * step / (1.0 + x * x);
            // printf("i = %3d, id = %3d\n", i, id);
        }

        #pragma omp critical
        pi += sum[id];  // parallelize computing sum, Summation inside parallel section
    }
    printf("pi = %6.12f\n", pi);
}
```

Mutual(互斥) exclusion: Only one thread at a time can enter a `critical` region. (Threads wait their turn)

> 至此，可以将后续for 1000的sequential section合并到Parallel section当中，提升了效率。

## Deadlock & Livelock

> 在引入Lock之后，可以解决race condition的问题，但是又引入了新的问题，死锁(Deadlock)和活锁(Livelock)

Deadlock: a system state in which no progress is possible

> 死锁是指多个操作单元相互等待，导致整个系统停止。而活锁则是类似的概念，但在活锁中，尽管存在动作，但仍然被卡住了。死锁是双方互相等待，而没有任何进展。

### Deadlock

如下是一个现实生活中死锁的例子，四个方向的车都无法动弹。

![traffic deadlock](.image/image-20240701165754626.png)

以下是著名的死锁问题，哲学家就餐问题。

Dining Philosopher's Problem:

- Think until the left fork is available; when it is, pick it up
- Think until the right fork is available; when it is, pick it up
- When both forks are held, eat for a fixed amount of time
- Then, put the right fork down
- Then, put the left fork down
- Repeat from the beginning

![Dining Philosopher's Problem](.image/image-20240701165743684.png)

出现的问题是，如果每个人都拿起左边的fork，那么所有人都会在等待右边的fork，此时所有人都陷入到死锁的状态，都无法运动。

### Livelock

假设两个机器人以相对的方向走同一时间只允许两个人通过的通道，他们一开始彼此挡住了，然后每过相同的时间就换一个位置。

由于两个机器人移动的时间是一样的，所以总是处于被挡的状态，即使双方一直在移动，但是仍然无法前进。

这就是活锁。

---

> deadlock（死锁）和livelock（活锁）都是与多线程或进程管理相关的重要概念。
>
> 1. **死锁（Deadlock）**：
>    死锁指的是系统中的几个进程或线程因为彼此占有了对方所需的资源而无法继续执行的状态。死锁通常发生在多个进程同时等待系统资源（如内存、文件、设备等）的情况下，每个进程都在等待其他进程释放它所需要的资源，导致所有进程都无法继续运行。要解决死锁，常见的方法包括资源分配策略、资源预先分配和资源的超时释放等。
>
> 2. **活锁（Livelock）**：
>    活锁是指系统中的几个进程或线程在尝试解决死锁或资源争夺问题时，反复改变状态而无法继续正常执行的状态。不同于死锁，活锁中的进程或线程并不是被阻塞，它们在不断重试中消耗资源，却无法取得进展。解决活锁的方法通常涉及到引入随机性或者改变进程的执行顺序，以避免进程陷入无休止的竞争状态。
>

死锁需要解决，但是本课程并不予讨论。

## OpenMP Timing

我们需要估计时间，用来测试不同参数下哪个并行程序运行的更快。

> 这与CS61A、B中进行算法分析并计算基本的原始操作次数，从而得出所谓的运行时间，即原始步骤的数量（其实也就是时间复杂度）。这个数量是随着输入规模增长而增长的。
>
> 但是在并行线程中，我们不太关心每个线程执行了多少步骤，而是比较不同并行化的速度。

之前说过，不要使用普通的时间记数，因为那样计算时间也是需要线程的。下面是OpenMP提供的方式。

Elapsed(已经过去的) wall clock time:

```c
double omp_get_wtime(void); 
```

- Returns elapsed wall clock time in seconds
- Time is measured per thread, no guarantee can be made that two distinct threads measure the same time
- Time is measured from "some time in the past", so subtract results of two calls to `omp_get_wtime` to get elapsed time

可以两次调用这个函数，然后相减得到执行的时间。

> 在计算机领域中，"wall clock time"（墙上钟时间）通常指的是从一个事件或操作开始到完成所经过的实际时间，即我们通常所说的"实际时间"或"挂钟时间"。它是指在现实世界中真正流逝的时间，包括所有可能的延迟、等待和计算时间，与计算机系统中的其他抽象时间测量（如CPU时间）有所区别。 Wall clock time是指用来度量一段程序实际运行所需的时间，包括等待输入/输出、线程切换等。

## Load-reserve, store-conditional

如下是在diss13中对于进程之间同步的第二种方式的补充

The benefits of multi-threading programming come only after you understand concurrency. Here are **two of the most common concurrency issues**:

1. **Cache-incoherence**: each hardware thread has its own cache, hence data modified in one thread may not be immediately reflected in the other. This can often be solved by bypassing the cache and writing directly to memory, i.e. using volatile keywords in many languages.(这个在lec35.3中会将)
2. **Read-modify-write**: Read-modify-write is a very common pattern in programming. In the context of multi-threading programming, the **interleaving(交错)** of R, M, W stages often produces a lot of issues.

> 这两种问题本质都是一样的，都是多线程场景下的一致性问题，因此会放到一个模块中讲

In order to solve the problems created by Read-modify-write, we have to rely on the idea of **uninterrupted execution**, also known as atomic execution.

In RISC-V, we have two categories of atomic instructions:

1. **Load-reserve, store-conditional**: allows us to have uninterrupted execution across multiple instructions
2. **Amo.swap**: allows for uninterrupted **memory operations** within a single instruction

> Amo操作就是针对的内存，并不是针对寄存器

Both of these can be used to achieve atomic primitives. Here are examples for each:

```Assembly
# Test-and-set, Amo.swap方式
Start: addi t0 x0 1 # Locked = 1
amoswap.w.aq t1 t0 (a0)
bne t1 x0 Start
# If the lock is not free, retry
... # Critical section
amoswap.w.rl x0 x0 (a0) # Release lock
```

```Assembly
Compare-and-swap
# a0 holds address of memory location
# a1 holds expected value
# a2 holds desired value
# a0 holds return value, 0 if successful, !0
otherwise
cas:
lr.w t0, (a0) # Load original value.
bne t0, a1, fail # Doesnt match, so fail.
sc.w a0, a2, (a0) # Try to update.
jr ra # Return.
fail:
li a0, 1 # Set return to failure.
jr ra # Return.
```

Instruction definitions:

- `lr`(Load-reserve): Loads the four bytes at `M[R[rs1]]`, writes them to `R[rd]`, signextending the result and registers a reservation on that word in memory
- `rc`(Store-conditional) `rd, rs2, (rs1)`: Stores the four bytes in register `R[rs2]` to `M[R[rs1]]`, provided there exists a load reservation on that memory address. Writes 0 to `R[rd]` if the store succeeded, or a nonzero error code otherwise.
- Amoswap rd, rs2, (rs1): Atomically, puts the sign-extended word located at `M[R[rs1]]` into `R[rd]` and puts `R[rs2]` into `M[R[rs1]]`.

Explanations for both methodologies:

- **Test-and-set**: We have a lock stored at the address specified by a0. We utilize amoswap to put in 1 and get the old value. If the old value was a 1, we would not have changed the value of the lock and we will realize that someone currently has the lock. If the old value was a 0, we will have just "locked" the lock and can continue with the critical section. When we are done, we put a 0 back into the lock to "unlock" it.
- **Compare-and-swap**: CAS tries to first reserve the memory and gets the value stored and compares it to the expected value. If the expected value and the value that was stored do not match, the entire process fails and we must restart to update based on the new information. Otherwise, we register a reservation on the memory and try to store the new value. If the exit code is nonzero, something went wrong with the store and we must retry the entire LR/SC process. Otherwise with a zero exit code, we continue into the critical section, then release the lock.

下面是ChatGPT对于**Load-reserve, store-conditional**的解释:

Load-reserve (LR) 和 store-conditional (SC) 是一对用于实现原子操作的指令，通常用于多处理器系统中的同步原语。它们在处理器架构中提供了一种机制，帮助处理器在并发情况下协调对共享数据的访问。

### Load-reserve (LR)

Load-reserve (也叫 load-linked, LL) 指令执行以下操作：
1. 读取内存地址中的值并将其加载到寄存器中。
2. 标记该内存地址为“保留”（reserve），表示接下来的 store-conditional (SC) 操作要检查这个地址是否被其他处理器修改过。

### Store-conditional (SC)

Store-conditional 指令执行以下操作：
1. 检查之前由 load-reserve 标记的内存地址是否仍然保留（即是否未被其他处理器写入）。
2. 如果内存地址仍然保留，则将寄存器中的值存储到该内存地址中，并返回成功标志。
3. 如果内存地址不再保留（即被其他处理器修改过），则 store-conditional 操作失败，不执行存储操作，并返回失败标志。

### 用法

LR/SC 指令通常配对使用，用于实现原子性操作，如比较并交换（Compare-and-Swap, CAS）等。这种配对使用保证了在多处理器环境中，不同处理器之间可以协调访问共享数据，避免数据竞争（data race）问题。

### 示例

以下是一个使用 Load-reserve 和 Store-conditional 的示例伪代码，用于实现一个简单的原子加法操作：

```assembly
atomic_add:
    LR R1, (R2)       # Load-reserve: 将内存地址 R2 的值加载到寄存器 R1，并标记 R2
    ADD R1, R1, R3    # 将 R1 的值加上 R3
    SC R1, (R2)       # Store-conditional: 如果 R2 仍然保留，则将 R1 存储到 R2
    BEQZ R1, atomic_add # 如果 store-conditional 失败（R1 为 0），则重试
    RET
```

在这个例子中：
1. `LR` 指令从内存地址 `R2` 读取值并存储到 `R1`，并标记 `R2` 为保留。
2. `ADD` 指令将 `R3` 加到 `R1`。
3. `SC` 指令检查 `R2` 是否仍然保留。如果是，则将 `R1` 的值存储回 `R2`；否则，`SC` 失败。
4. 如果 `SC` 失败，程序会跳回 `atomic_add`，重新尝试整个过程。

这种方式确保了加法操作的原子性，即使在多个处理器同时尝试修改同一个内存地址的情况下，也能保证结果的正确性。
